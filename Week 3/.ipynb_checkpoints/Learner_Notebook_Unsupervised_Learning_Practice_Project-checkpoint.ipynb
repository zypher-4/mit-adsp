{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "36Ay5AN2k7XP"
   },
   "source": [
    "# **Unsupervised Learning Practice Project: Fantasy Sports Clustering Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0NOHZohmk7XR"
   },
   "source": [
    "--------------------------------\n",
    "## **Context** \n",
    "-------------------------------\n",
    "\n",
    "Fantasy sports are online gaming platforms where participants draft and manage virtual teams of real professional sports players. Based on the performance of the players in the real world, players are allotted points in the fantasy sports platform every match. The objective is to create the best possible team with a fixed budget to score maximum fantasy points, and users compete against each other over an entire sports league or season. Some of these fantasy sports require actual financial investments for participation, with the chances of winning monetary rewards as well as free matchday tickets on a periodic basis.\n",
    "\n",
    "The fantasy sports market has seen tremendous growth over the past few years, with a valuation of \\\\$18.6 billion in 2019. The football (soccer) segment led in terms of market share in 2019, with over 8 million participants worldwide, and is expected to retain its dominance over the next couple of years. Digitalization is one of the primary factors driving the growth of the fantasy sports market as it allows participants the opportunity to compete on a global level and test their skills. With an increase in smartphone usage and availability of fantasy sports apps, this market is expected to witness a globe surge and reach a \\\\$48.6 billion valuation by 2027.\n",
    "\n",
    "\n",
    "----------------------------\n",
    "## **Objective**\n",
    "-----------------------------\n",
    "\n",
    "OnSports is a fantasy sports platform that has fantasy leagues for many different sports and has witnessed an increasing number of participants globally over the past 5 years. For each player, a price is set at the start, and the price keeps changing over time based on the performance of the players in the real world. With the new English Premier League season about to start, they have collected data from the past season and want to analyze it to determine the price of each player for the start of the new season. OnSports have hired you as a data scientist and asked you to conduct a cluster analysis to identify players of different potentials of each player based on previous season performance. This will help them understand the patterns in player performances and fantasy returns and decide the exact price to be set for each player for the upcoming football season.\n",
    "\n",
    "--------------------------\n",
    "## **Data Description**\n",
    "--------------------------\n",
    "\n",
    "- **Player_Name:** Name of the player.\n",
    "- **Club:** Club in which the player plays.\n",
    "- **Position:** Position in which the player plays.\n",
    "- **Goals_Scored:** Number of goals scored by the player in the previous season.\n",
    "- **Assists:** Number of passes made by the player leading to goals in the previous season.\n",
    "- **Total_Points:** Total number of fantasy points scored by the player in the previous season.\n",
    "- **Minutes:** Number of minutes played by the player in the previous season.\n",
    "- **Goals_Conceded:** Number of goals conceded by the player in the previous season.\n",
    "- **Creativity:** A score, computed using a range of stats, that assesses player performance in terms of producing goalscoring opportunities for other players.\n",
    "- **Influence:** A score, computed using a range of stats, that evaluates a player's impact on a match, taking into account actions that could directly or indirectly affect the match outcome.\n",
    "- **Threat:** A score, computed using a range of stats, that gauges players who are most likely to score goals.\n",
    "- **Bonus:** Total bonus points received. The three best performing players in each match receive additional bonus points based on a score computed using a range of stats. 3 points are awarded to the highest scoring player, 2 to the second best, and 1 to the third.\n",
    "- **Clean_Sheets:** Number of matches without conceding a goal in the previous season."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3_UG-8Ck7XR"
   },
   "source": [
    "## **Importing the necessary libraries and overview of the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jsJAFMzVk7XS"
   },
   "outputs": [],
   "source": [
    "# Libraries to help with reading and manipulating data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Libraries to help with data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style='darkgrid')\n",
    "\n",
    "# Removes the limit for the number of displayed columns\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Sets the limit for the number of displayed rows\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "\n",
    "# To scale the data using z-score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# To compute distances\n",
    "from scipy.spatial.distance import cdist, pdist\n",
    "\n",
    "# To perform K-means clustering and compute silhouette scores\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# To import K-Medoids\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "\n",
    "# To import DBSCAN and Gaussian Mixture\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# To perform hierarchical clustering, compute cophenetic correlation, and create dendrograms\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, cophenet\n",
    "\n",
    "# To suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hQqKsK4Xk7XT"
   },
   "outputs": [],
   "source": [
    "# Complete the code to import the data\n",
    "data = pd.read_csv('data/fpl_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player_Name</th>\n",
       "      <th>Club</th>\n",
       "      <th>Position</th>\n",
       "      <th>Goals_Scored</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Total_Points</th>\n",
       "      <th>Minutes</th>\n",
       "      <th>Goals_Conceded</th>\n",
       "      <th>Creativity</th>\n",
       "      <th>Influence</th>\n",
       "      <th>Threat</th>\n",
       "      <th>Bonus</th>\n",
       "      <th>Clean_Sheets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alex Runnarsson</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Goalkeeper</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alexandre Lacazette</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Forward</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>129</td>\n",
       "      <td>1916</td>\n",
       "      <td>21</td>\n",
       "      <td>307.4</td>\n",
       "      <td>602.4</td>\n",
       "      <td>797</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bernd Leno</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Goalkeeper</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131</td>\n",
       "      <td>3131</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>702.2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bukayo Saka</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Midfielder</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>114</td>\n",
       "      <td>2554</td>\n",
       "      <td>31</td>\n",
       "      <td>650.6</td>\n",
       "      <td>493.0</td>\n",
       "      <td>984</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Calum Chambers</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Defender</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>751</td>\n",
       "      <td>10</td>\n",
       "      <td>169.4</td>\n",
       "      <td>171.8</td>\n",
       "      <td>77</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Player_Name     Club    Position  Goals_Scored  Assists  \\\n",
       "0      Alex Runnarsson  Arsenal  Goalkeeper             0        0   \n",
       "1  Alexandre Lacazette  Arsenal     Forward            13        3   \n",
       "2           Bernd Leno  Arsenal  Goalkeeper             0        0   \n",
       "3          Bukayo Saka  Arsenal  Midfielder             5        5   \n",
       "4       Calum Chambers  Arsenal    Defender             0        3   \n",
       "\n",
       "   Total_Points  Minutes  Goals_Conceded  Creativity  Influence  Threat  \\\n",
       "0             1       15               0         0.0       16.6       0   \n",
       "1           129     1916              21       307.4      602.4     797   \n",
       "2           131     3131              37         0.0      702.2       2   \n",
       "3           114     2554              31       650.6      493.0     984   \n",
       "4            36      751              10       169.4      171.8      77   \n",
       "\n",
       "   Bonus  Clean_Sheets  \n",
       "0      0             0  \n",
       "1     21             7  \n",
       "2     11            11  \n",
       "3      8             8  \n",
       "4      3             2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "NGz-Y3jUk7XT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(476, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of the data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xsOjf9etk7XT"
   },
   "outputs": [],
   "source": [
    "# Let's view a sample of the data\n",
    "data.sample(n = 10, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9NRu9jiSk7XT"
   },
   "outputs": [],
   "source": [
    "# Checking the column names and datatypes\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0-MJASJLk7XT"
   },
   "outputs": [],
   "source": [
    "# Copying the data to another variable to avoid any changes to original data\n",
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WapzauPrhmV7"
   },
   "outputs": [],
   "source": [
    "# Check for duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8akeocN7k7XU"
   },
   "outputs": [],
   "source": [
    "# Check for missing values in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DhPuzWO7hmV8"
   },
   "source": [
    "## **Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eW4-5-GUhmV8"
   },
   "source": [
    "**Let's check the statistical summary of the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zYiLKmcAk7XU"
   },
   "outputs": [],
   "source": [
    "df.describe(_____).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UcY8-pNak7XU"
   },
   "source": [
    "**Observations and Insights: _____**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wVDWkonWk7XU"
   },
   "source": [
    "### **Univariate Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ccnxMhFAk7XU"
   },
   "outputs": [],
   "source": [
    "# Function to plot a boxplot and a histogram along the same scale\n",
    "\n",
    "\n",
    "def histogram_boxplot(data, feature, figsize = (12, 7), kde = False, bins = None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Boxplot and histogram combined\n",
    "\n",
    "    data: dataframe\n",
    "    feature: dataframe column\n",
    "    figsize: size of figure (default (12, 7))\n",
    "    kde: whether to the show density curve (default False)\n",
    "    bins: number of bins for histogram (default None)\n",
    "    \"\"\"\n",
    "    \n",
    "    f2, (ax_box2, ax_hist2) = plt.subplots(\n",
    "        nrows = 2,  # Number of rows of the subplot grid= 2\n",
    "        sharex = True,  # X-axis will be shared among all subplots\n",
    "        gridspec_kw = {\"height_ratios\": (0.25, 0.75)},\n",
    "        figsize = figsize,\n",
    "    )  # Creating the 2 subplots\n",
    "    sns.boxplot(\n",
    "        data = data, x = feature, ax = ax_box2, showmeans = True, color = \"violet\"\n",
    "    )  # Boxplot will be created and a star will indicate the mean value of the column\n",
    "    sns.histplot(\n",
    "        data = data, x = feature, kde = kde, ax = ax_hist2, bins = bins, palette = \"winter\"\n",
    "    ) if bins else sns.histplot(\n",
    "        data = data, x = feature, kde = kde, ax = ax_hist2\n",
    "    )  # For histogram\n",
    "    ax_hist2.axvline(\n",
    "        data[feature].mean(), color = \"green\", linestyle = \"--\"\n",
    "    )  # Add mean to the histogram\n",
    "    ax_hist2.axvline(\n",
    "        data[feature].median(), color = \"black\", linestyle = \"-\"\n",
    "    )  # Add median to the histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z2SnZ1EJk7XU"
   },
   "source": [
    "**`Goals_Scored`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FikYoRq3k7XV"
   },
   "outputs": [],
   "source": [
    "histogram_boxplot(df, 'Goals_Scored')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xN4E8giPk7XV"
   },
   "source": [
    "**`Assists`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b5qALv9Ak7XV"
   },
   "outputs": [],
   "source": [
    "histogram_boxplot(_______)  # Complete the code to create histogram_boxplot for 'Assists'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vYpK1G4Zk7XV"
   },
   "outputs": [],
   "source": [
    "# Plot the histogram and the boxplot for 'Goals_Conceded'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UQR5dqZRk7XV"
   },
   "outputs": [],
   "source": [
    "# Plot the histogram and the boxplot for 'Clean_Sheets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J15HHJe0k7XV"
   },
   "outputs": [],
   "source": [
    "# Plot the histogram and the boxplot for 'Minutes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "djoYe7kQk7XV"
   },
   "outputs": [],
   "source": [
    "# Plot the histogram and the boxplot for 'Total_Points'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LyHwhZC2k7XV"
   },
   "outputs": [],
   "source": [
    "# Plot the histogram and the boxplot for 'Creativity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Sda-DYEk7XV"
   },
   "outputs": [],
   "source": [
    "# Plot the histogram and the boxplot for 'Influence'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ex8wYY6fk7XV"
   },
   "outputs": [],
   "source": [
    "# Plot the histogram and the boxplot for 'Threat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uLD35CPpk7XW"
   },
   "outputs": [],
   "source": [
    "# Plot the histogram and the boxplot for 'Bonus'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KMtmx4x5k7XW"
   },
   "source": [
    "**Observations and Insights for all the plots: _____**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r7l7EonSk7XW"
   },
   "outputs": [],
   "source": [
    "# Function to create labeled barplots\n",
    "\n",
    "\n",
    "def labeled_barplot(data, feature, perc = False, n = None):\n",
    "    \"\"\"\n",
    "    Barplot with percentage at the top\n",
    "\n",
    "    data: dataframe\n",
    "    feature: dataframe column\n",
    "    perc: whether to display percentages instead of count (default is False)\n",
    "    n: displays the top n category levels (default is None, i.e., display all levels)\n",
    "    \"\"\"\n",
    "\n",
    "    total = len(data[feature])  # Length of the column\n",
    "    count = data[feature].nunique()\n",
    "    if n is None:\n",
    "        plt.figure(figsize = (count + 1, 5))\n",
    "    else:\n",
    "        plt.figure(figsize = (n + 1, 5))\n",
    "\n",
    "    plt.xticks(rotation = 90, fontsize = 15)\n",
    "    ax = sns.countplot(\n",
    "        data = data,\n",
    "        x = feature,\n",
    "        palette = \"Paired\",\n",
    "        order = data[feature].value_counts().index[:n].sort_values(),\n",
    "    )\n",
    "\n",
    "    for p in ax.patches:\n",
    "        if perc == True:\n",
    "            label = \"{:.1f}%\".format(\n",
    "                100 * p.get_height() / total\n",
    "            )  # Percentage of each class of the category\n",
    "        else:\n",
    "            label = p.get_height()  # Count of each level of the category\n",
    "\n",
    "        x = p.get_x() + p.get_width() / 2  # Width of the plot\n",
    "        y = p.get_height()  # Height of the plot\n",
    "\n",
    "        ax.annotate(\n",
    "            label,\n",
    "            (x, y),\n",
    "            ha = \"center\",\n",
    "            va = \"center\",\n",
    "            size = 12,\n",
    "            xytext = (0, 5),\n",
    "            textcoords = \"offset points\",\n",
    "        )  # Annotate the percentage\n",
    "\n",
    "    plt.show()  # Show the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ms9PH6z1k7XW"
   },
   "source": [
    "**`Club`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KwrKGj0Ck7XW"
   },
   "outputs": [],
   "source": [
    "labeled_barplot(df, 'Club')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3mI6X83k7XW"
   },
   "source": [
    "**`Position`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qbJBiljGk7XX"
   },
   "outputs": [],
   "source": [
    "labeled_barplot('_______')  # Complete the code to create a labelled barplot for 'Position'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txnqa8Hbk7XX"
   },
   "source": [
    "**Observations and Insights:__**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ga_huJrnhmWE"
   },
   "source": [
    "### **Bivariate Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YreKvji3k7XX"
   },
   "source": [
    "**We are done with univariate analysis. Let's explore the data a bit more with bivariate analysis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BpJxawjAhmWE"
   },
   "outputs": [],
   "source": [
    "# Correlation check\n",
    "cols_list = df.select_dtypes(include = np.number).columns.tolist()\n",
    "\n",
    "plt.figure(figsize = (15, 7))\n",
    "\n",
    "sns.heatmap(\n",
    "    df[cols_list].corr(numeric_only = True), annot = True, vmin = -1, vmax = 1, fmt = \".2f\", cmap = \"Spectral\"\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-DF8f77ak7Xb"
   },
   "source": [
    "**Observations and Insights:__**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9ihFUcvk7Xb"
   },
   "source": [
    "**Let's check players from which team have scored the most fantasy points on average.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_fBiYL6bk7Xc"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 8))\n",
    "\n",
    "sns.barplot(data = df, x = ___ , y = ___ , errorbar=('ci', False))  # Complete the code to choose the right variables\n",
    "\n",
    "plt.xticks(rotation = 90) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8RuHATjk7Xc"
   },
   "source": [
    "**We know that players in different positions have specific roles to play in a team. Let's check players in which positions tend to score more fantasy points on average.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ok_tmygik7Xc"
   },
   "outputs": [],
   "source": [
    "# Complete the code with the right variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IsTWLwaWk7Xc"
   },
   "source": [
    "**To effectively utilize their squad depth, managers often rotate the squad to keep key players in shape for tougher games. Let's check the total number of minutes played, on average, across different positions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ubc0i7ZSk7Xc"
   },
   "outputs": [],
   "source": [
    "# Complete the code with the right variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44FGIFyJk7Xc"
   },
   "source": [
    "**Every point counts in fantasy sports and getting bonus points for a player is always a treat. Let's check which team's players have secured the most bonus points, on average, last season.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2qGmtQNVk7Xc"
   },
   "outputs": [],
   "source": [
    "# Complete the code with the right variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MSwINjmBk7Xc"
   },
   "source": [
    "**Let's see which players scored the most fantasy points last season for different positions of play.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pfpJEp9nk7Xc"
   },
   "outputs": [],
   "source": [
    "pos_list = df.Position.unique().tolist()\n",
    "best_df = pd.DataFrame()\n",
    "\n",
    "for pos in pos_list:\n",
    "    df_aux = df[df.Position == pos]\n",
    "    best_df = pd.concat([best_df, df_aux[df_aux.Total_Points == df_aux.Total_Points.max()][['Player_Name', 'Club', 'Position', 'Total_Points']]])\n",
    "\n",
    "best_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "awpdTLLBk7Xd"
   },
   "source": [
    "**Let's see the top 10 players with the most fantasy points last season for different positions of play.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mG5Pe0i0k7Xd"
   },
   "outputs": [],
   "source": [
    "best10_df = pd.DataFrame()\n",
    "\n",
    "for pos in pos_list:\n",
    "    df_aux = df[df.Position == pos]\n",
    "    best10_df = pd.concat([best10_df, df_aux.sort_values('Total_Points', ascending=False).reset_index(drop=True).loc[:10, ['Player_Name', 'Club', 'Position', 'Total_Points']]])\n",
    "\n",
    "best10_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kB5W94Apk7Xd"
   },
   "source": [
    "### **Outlier Check**\n",
    "\n",
    "- Let's plot the boxplots of all numerical columns to check for outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kg-yXiBkk7Xd"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 10))\n",
    "\n",
    "numeric_columns = df.select_dtypes(include = np.number).columns.tolist()\n",
    "\n",
    "for i, variable in enumerate(numeric_columns):\n",
    "    \n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    \n",
    "    plt.boxplot(df[variable], whis = 1.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.title(variable)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6cWGKgxk7Xd"
   },
   "source": [
    "### **Scaling**\n",
    "\n",
    "- Let's scale the data before we proceed with clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HYq9leNlk7Xd"
   },
   "outputs": [],
   "source": [
    "# Scaling the data before clustering\n",
    "scaler = ________ # Initialize the Standard Scaler\n",
    "\n",
    "subset = ___  # Complete the code to get the data with numerical features\n",
    "\n",
    "subset_scaled = ______ # Fit_transform the scaler function on data subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Egxt8kq1k7Xd"
   },
   "outputs": [],
   "source": [
    "# Creating a dataframe of the scaled data\n",
    "subset_scaled_df = pd.DataFrame(subset_scaled, columns = subset.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upKrl7bqk7Xd"
   },
   "source": [
    "### **Applying PCA**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OJH9WCEsk7Xd"
   },
   "outputs": [],
   "source": [
    "# Defining the number of principal components to generate\n",
    "n = subset.shape[1]                                    # Storing the number of variables in the subset data\n",
    "\n",
    "pca = ____________                                     # Initialize PCA with n_components = n and random_state = 1\n",
    "\n",
    "data_pca = pd.DataFrame(pca.____________)              # Fit_transform PCA on the scaled data\n",
    "\n",
    "# The percentage of variance explained by each principal component is stored\n",
    "exp_var = pca.explained_variance_ratio_                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9rrkKdzak7Xd"
   },
   "source": [
    "## **K-Means Clustering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zCHi9hKHk7Xe"
   },
   "outputs": [],
   "source": [
    "k_means_df = data_pca.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xFZsNL0Bk7Xe"
   },
   "outputs": [],
   "source": [
    "clusters = range(1, 15)\n",
    "meanDistortions = []\n",
    "\n",
    "for k in clusters:\n",
    "    \n",
    "    model = KMeans(n_clusters = k, random_state = 1, n_init = \"auto\")\n",
    "    \n",
    "    model.fit(data_pca)\n",
    "    \n",
    "    prediction = model.predict(k_means_df)\n",
    "    \n",
    "    distortion = (\n",
    "        sum(np.min(cdist(k_means_df, model.cluster_centers_, \"euclidean\"), axis = 1))\n",
    "        / k_means_df.shape[0]\n",
    "    )\n",
    "\n",
    "    meanDistortions.append(distortion)\n",
    "\n",
    "    print(\"Number of Clusters:\", k, \"\\tAverage Distortion:\", distortion)\n",
    "\n",
    "plt.plot(clusters, meanDistortions, \"bx-\")\n",
    "\n",
    "plt.xlabel(\"k\")\n",
    "\n",
    "plt.ylabel(\"Average Distortion\")\n",
    "\n",
    "plt.title(\"Selecting k with the Elbow Method\", fontsize = 20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v4YPhFLck7Xe"
   },
   "source": [
    "**Observations and Insights:**\n",
    "\n",
    "- We will move ahead with k = 4. **What can be the reason for the same?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wNlgzXDYk7Xe"
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(______, random_state = 1, n_init = \"auto\") # Create K-Means with nclusters = 4\n",
    "\n",
    "kmeans.fit(k_means_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KaMUds34k7Xe"
   },
   "outputs": [],
   "source": [
    "# Creating a copy of the original data\n",
    "df1 = df.copy()\n",
    "\n",
    "# Adding K-Means cluster labels to the K-Means dataframe\n",
    "k_means_df[\"KM_segments\"] = kmeans.labels_\n",
    "\n",
    "# Adding K-Means cluster labels to the original dataframe\n",
    "df1[\"KM_segments\"] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IxSYhJVOk7Xe"
   },
   "source": [
    "### **Cluster Profiling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CwKexcUJk7Xe"
   },
   "outputs": [],
   "source": [
    "km_cluster_profile = df1.groupby( ____ ).mean(numeric_only = True)  # Complete the code to groupby the cluster labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hCvuAKRHk7Xe"
   },
   "outputs": [],
   "source": [
    "# Creating the \"count_in_each_segment\" feature in K-Means cluster profile\n",
    "\n",
    "km_cluster_profile[\"count_in_each_segment\"] = (\n",
    "    df1.groupby( ______ )[\"Total_Points\"].count().values)  # Complete the code to groupby the cluster labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xtoZsYDek7Xe"
   },
   "outputs": [],
   "source": [
    "# Highlight the maximum average value among all the clusters for each of the variables\n",
    "km_cluster_profile.style.highlight_max(color = \"lightgreen\", axis = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x0CTTsa0k7Xe"
   },
   "outputs": [],
   "source": [
    "# Complete the code to print the players in each cluster. Hint: Use the KM_segments feature\n",
    "\n",
    "for cl in df1[ ___ ].unique(): \n",
    "    print(\"In cluster {}, the following players are present:\".format(cl))\n",
    "    print(df1[df1[ ____ ] == cl][\"Player_Name\"].unique())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wZrMiMgak7Xf"
   },
   "outputs": [],
   "source": [
    "df1.groupby([\"KM_segments\", \"Position\"])['Player_Name'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKX1lFTEk7Xf"
   },
   "source": [
    "**Let's plot the boxplot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HuvXBzOkk7Xf"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 4, figsize = (20, 20))\n",
    "counter = 0\n",
    "\n",
    "for ii in range(3):\n",
    "    for jj in range(4):\n",
    "        if counter < 10:\n",
    "            sns.boxplot(\n",
    "                ax = axes[ii][jj],\n",
    "                data = df1,\n",
    "                y = df1.columns[3 + counter],\n",
    "                x = \"KM_segments\",\n",
    "            )\n",
    "            counter = counter + 1\n",
    "\n",
    "fig.tight_layout(pad = 3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AU6tP05_k7Xf"
   },
   "source": [
    "### **Characteristics of each cluster:___**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gT445vc9k7Xf"
   },
   "source": [
    "## **K-Medoids Clustering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YwuJu36Tk7Xf"
   },
   "outputs": [],
   "source": [
    "kmed_df = data_pca.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5MB8_6L7k7Xf"
   },
   "outputs": [],
   "source": [
    "kmed = KMedoids(______, random_state = 1) # Create K-Medoids with nclusters = 4\n",
    "kmed.fit(kmed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S-7M0nRlk7Xf"
   },
   "outputs": [],
   "source": [
    "# Creating a copy of the original data\n",
    "df2 = df.copy()\n",
    "\n",
    "# Add K-Medoids cluster labels to K-Medoids data\n",
    "k_med_df[\"KMed_segments\"] = ________\n",
    "\n",
    "# Add K-Medoids cluster labels to original data\n",
    "df2[\"KMed_segments\"] =  _________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eSfvSng7k7Xf"
   },
   "source": [
    "### **Cluster Profiling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vuAQPieak7Xf"
   },
   "outputs": [],
   "source": [
    "# Take the cluster-wise mean of all the variables. Hint: First group 'df2' by cluster labels column and then find mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XqKdnX1zk7Xg"
   },
   "outputs": [],
   "source": [
    "# Create the \"count_in_each_segment\" column in K-Medoids cluster profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JxPsO_j6k7Xg"
   },
   "outputs": [],
   "source": [
    "# Highlight the maximum average value among all the clusters for each of the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rsbKmABKk7Xg"
   },
   "outputs": [],
   "source": [
    "# Complete the code to print the players in each cluster. Hint: Use the KMed_segments feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LXOXfp8Bk7Xg"
   },
   "source": [
    "**Let's plot the boxplot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MsMK3gIEk7Xg"
   },
   "outputs": [],
   "source": [
    "# Create boxplot for each of the variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oP8mRbXak7Xg"
   },
   "source": [
    "### **Characteristics of each cluster:___**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDt_wUDsk7Xg"
   },
   "source": [
    "### **Comparison of cluster profiles from K-Means and K-Medoids:_______________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufEDqnT6k7Xg"
   },
   "source": [
    "##  **Hierarchical Clustering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q_QV1pGqk7Xg"
   },
   "outputs": [],
   "source": [
    "hc_df = data_pca.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TUcRjFbDJlAk"
   },
   "outputs": [],
   "source": [
    "hc_df1 = hc_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SmU5EObNk7Xh"
   },
   "outputs": [],
   "source": [
    "# List of distance metrics\n",
    "distance_metrics = [\"euclidean\", \"chebyshev\", \"mahalanobis\", \"cityblock\"]\n",
    "\n",
    "# List of linkage methods\n",
    "linkage_methods = [\"single\", \"complete\", \"average\", \"weighted\"]\n",
    "\n",
    "high_cophenet_corr = 0\n",
    "high_dm_lm = [0, 0]\n",
    "\n",
    "for dm in distance_metrics:\n",
    "    for lm in linkage_methods:\n",
    "        Z = linkage(hc_df1, metric = dm, method = lm)\n",
    "        c, coph_dists = cophenet(Z, pdist(hc_df))\n",
    "        print(\n",
    "            \"Cophenetic correlation for {} distance and {} linkage is {}.\".format(\n",
    "                dm.capitalize(), lm, c\n",
    "            )\n",
    "        )\n",
    "        if high_cophenet_corr < c:\n",
    "            high_cophenet_corr = c\n",
    "            high_dm_lm[0] = dm\n",
    "            high_dm_lm[1] = lm\n",
    "            \n",
    "# Printing the combination of distance metric and linkage method with the highest cophenetic correlation\n",
    "print('*'*100)\n",
    "print(\n",
    "    \"Highest cophenetic correlation is {}, which is obtained with {} distance and {} linkage.\".format(\n",
    "        high_cophenet_corr, high_dm_lm[0].capitalize(), high_dm_lm[1]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0E2DMI2k7Xh"
   },
   "source": [
    "**Let's explore different linkage methods with Euclidean distance only.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SvCL3kX5k7Xh"
   },
   "outputs": [],
   "source": [
    "# List of linkage methods\n",
    "linkage_methods = [\"single\", \"complete\", \"average\", \"centroid\", \"ward\", \"weighted\"]\n",
    "\n",
    "high_cophenet_corr = 0\n",
    "high_dm_lm = [0, 0]\n",
    "\n",
    "for lm in linkage_methods:\n",
    "    Z = linkage(hc_df1, metric = \"euclidean\", method = lm)\n",
    "    c, coph_dists = cophenet(Z, pdist(hc_df))\n",
    "    print(\"Cophenetic correlation for {} linkage is {}.\".format(lm, c))\n",
    "    if high_cophenet_corr < c:\n",
    "        high_cophenet_corr = c\n",
    "        high_dm_lm[0] = \"euclidean\"\n",
    "        high_dm_lm[1] = lm\n",
    "        \n",
    "# Printing the combination of distance metric and linkage method with the highest cophenetic correlation\n",
    "print('*'*100)\n",
    "print(\n",
    "    \"Highest cophenetic correlation is {}, which is obtained with {} linkage.\".format(\n",
    "        high_cophenet_corr, high_dm_lm[1]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjgz6hkDk7Xh"
   },
   "source": [
    "**Let's view the dendrograms for the different linkage methods with Euclidean distance only.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v07EzEUdk7Xh"
   },
   "outputs": [],
   "source": [
    "# List of linkage methods\n",
    "linkage_methods = [\"single\", \"complete\", \"average\", \"centroid\", \"ward\", \"weighted\"]\n",
    "\n",
    "# Lists to save results of cophenetic correlation calculation\n",
    "compare_cols = [\"Linkage\", \"Cophenetic Coefficient\"]\n",
    "compare = []\n",
    "\n",
    "# To create a subplot image\n",
    "fig, axs = plt.subplots(len(linkage_methods), 1, figsize = (15, 30))\n",
    "\n",
    "# We will enumerate through the list of linkage methods above\n",
    "# For each linkage method, we will plot the dendrogram and calculate the cophenetic correlation\n",
    "for i, method in enumerate(linkage_methods):\n",
    "    Z = linkage(hc_df1, metric = \"euclidean\", method = method)\n",
    "\n",
    "    dendrogram(Z, ax = axs[i])\n",
    "    axs[i].set_title(f\"Dendrogram ({method.capitalize()} Linkage)\")\n",
    "\n",
    "    coph_corr, coph_dist = cophenet(Z, pdist(hc_df))\n",
    "    axs[i].annotate(\n",
    "        f\"Cophenetic\\nCorrelation\\n{coph_corr:0.2f}\",\n",
    "        (0.80, 0.80),\n",
    "        xycoords=\"axes fraction\",\n",
    "    )\n",
    "\n",
    "    compare.append([method, coph_corr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H4AQc8t7k7Xh"
   },
   "outputs": [],
   "source": [
    "# Create and print a dataframe to compare cophenetic correlations for different linkage methods\n",
    "df_cc = pd.DataFrame(compare, columns = compare_cols)\n",
    "df_cc = df_cc.sort_values(by = \"Cophenetic Coefficient\")\n",
    "df_cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tUMEee91k7Xh"
   },
   "outputs": [],
   "source": [
    "HCmodel = AgglomerativeClustering(n_clusters = ___ , metric = ___ , linkage = ___ )  # Complete the code to define the hierarchical clustering with average linkage\n",
    "HCmodel.fit(hc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lCI4VgbWk7Xi"
   },
   "outputs": [],
   "source": [
    "# Creating a copy of the original data\n",
    "df3 = df.copy()\n",
    "\n",
    "# Adding hierarchical cluster labels to the Heirarhical and original dataframes\n",
    "hc_df[\"HC_segments_L1\"] = _______________\n",
    "df3[\"HC_segments_L1\"] = _______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHCIWTKVk7Xi"
   },
   "source": [
    "### **Cluster Profiling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ofjcCmCGk7Xi"
   },
   "outputs": [],
   "source": [
    "# Take the cluster-wise mean of all the variables. Hint: First group 'df3' by cluster labels column and then find mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K8eJeYqvk7Xi"
   },
   "outputs": [],
   "source": [
    "# Create the \"count_in_each_segment\" column in hierarchical cluster profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FwGsim5Xk7Xi"
   },
   "outputs": [],
   "source": [
    "# Highlight the maximum average value among all the clusters for each of the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zCqlfArak7Xi"
   },
   "outputs": [],
   "source": [
    "# Complete the code to print the players in each cluster. Hint: Use the HC_segments feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "So_O1s0ck7Xi"
   },
   "source": [
    "**We see that most of the players have been grouped into one cluster, and there are two very sparse clusters. This clustering does not look good as the clusters do not have enough variability.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gzW7TiWBk7Xi"
   },
   "source": [
    "**Let us try using Ward linkage as it has more distinct and separated clusters (as seen from it's dendrogram before). 4 appears to be a good number of clusters from the dendrogram for Ward linkage.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zukPEe-AKBQs"
   },
   "outputs": [],
   "source": [
    "hc_df2 = data_pca.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tKRmVK1Mk7Xi"
   },
   "outputs": [],
   "source": [
    "HCmodel = AgglomerativeClustering(n_clusters = ___ , metric = ___ , linkage = ___ )  # Complete the code to define the hierarchical clustering with Ward Linkage\n",
    "HCmodel.fit(hc_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H1bJI16Rk7Xi"
   },
   "outputs": [],
   "source": [
    "# Creating a copy of the original data\n",
    "df3 = df.copy()\n",
    "\n",
    "# Adding hierarchical cluster labels to the Heirarhical and original dataframes\n",
    "hc_df[\"HC_segments_L2\"] = _______________\n",
    "df3[\"HC_segments_L2\"] = _______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kueg34Aik7Xi"
   },
   "source": [
    "### **Cluster Profiling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HIIRzQJuk7Xj"
   },
   "outputs": [],
   "source": [
    "# Take the cluster-wise mean of all the variables. Hint: First group 'df3' by cluster labels column and then find mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8qTpqAZOk7Xj"
   },
   "outputs": [],
   "source": [
    "# Create the \"count_in_each_segment\" column in hierarchical cluster profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "78qG6L03k7Xj"
   },
   "outputs": [],
   "source": [
    "# Highlight the maximum average value among all the clusters for each of the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9dzqXZTuk7Xj"
   },
   "outputs": [],
   "source": [
    "# Complete the code to print the players in each cluster. Hint: Use the HC_segments feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJF40Snbk7Xj"
   },
   "source": [
    "**Let's plot the boxplot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aAS5LQSZk7Xj"
   },
   "outputs": [],
   "source": [
    "# Create boxplot for each of the variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n8Qk7RFck7Xj"
   },
   "source": [
    "### **Characteristics of each cluster:___**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QonRIbMZk7Xj"
   },
   "source": [
    "### **Comparison of cluster profiles from Hierarchical and previous algorithms:___________________**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J32imV_9k7Xk"
   },
   "source": [
    "## **GMM clustering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PGgcUhTok7Xk"
   },
   "outputs": [],
   "source": [
    "gmm_df = data_pca.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bglxQL8uk7Xk"
   },
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(________, random_state = 1) # Initializing the Gaussian Mixture algorithm with n_components = 4\n",
    "\n",
    "gmm.fit(_____) # Fit the Gaussian Mixture algorithm on the gmm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_MHYobtk7Xk"
   },
   "source": [
    "### **Cluster Profiling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lD9vNwzvk7Xk"
   },
   "outputs": [],
   "source": [
    "# Creating a copy of the original data\n",
    "df4 = df.copy()\n",
    "\n",
    "# Adding gmm cluster labels to the GMM and original dataframes\n",
    "gmm_df[\"GMM_segments\"] = ____________\n",
    "df4[\"GMM_segments\"] = _______________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rtmM_Z34k7Xk"
   },
   "outputs": [],
   "source": [
    "# Take the cluster-wise mean of all the variables. Hint: First group 'df4' by cluster labels column and then find mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6EyqHWBlk7Xk"
   },
   "outputs": [],
   "source": [
    "# Create the \"count_in_each_segment\" column in gmm cluster profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sQai4HRok7Xk"
   },
   "outputs": [],
   "source": [
    "# Highlight the maximum average value among all the clusters for each of the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "De4Crj29k7Xk"
   },
   "outputs": [],
   "source": [
    "# Complete the code to print the players in each cluster. Hint: Use the GMM_segments feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cbTNQslTk7Xk"
   },
   "source": [
    "**Let's plot the boxplot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tpG3qYvKk7Xl"
   },
   "outputs": [],
   "source": [
    "# Create boxplot for each of the variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r72fQ2l3k7Xl"
   },
   "source": [
    "### **Characteristics of each cluster:___**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LaFlCqdk7Xl"
   },
   "source": [
    "### **Comparison of cluster profiles from GMM and previous algorithms:______________________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oa2NSU1ck7Xl"
   },
   "source": [
    "## **DBSCAN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lmgJ2ktLk7Xl"
   },
   "source": [
    "DBSCAN is a very powerful algorithm for finding high-density clusters, but the problem is determining the best set of hyperparameters to use with it. It includes two hyperparameters, `eps`, and `min samples`.\n",
    "\n",
    "Since it is an unsupervised algorithm, you have no control over it, unlike a supervised learning algorithm, which allows you to test your algorithm on a validation set. The approach we can follow is basically trying out a bunch of different combinations of values and finding the silhouette score for each of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "npZRdRRyk7Xl"
   },
   "source": [
    "### **What is the silhouette score?**\n",
    "\n",
    "Silhouette score is one of the methods for evaluating the quality of clusters created using clustering algorithms such as K-Means. The silhouette score is a measure of how similar an object is to its cluster (cohesion) compared to other clusters (separation). Silhouette score has a range of [-1, 1].\n",
    "\n",
    "* Silhouette coefficients near +1 indicate that the sample is far away from the neighboring clusters. \n",
    "* Silhouette score near -1 indicates that those samples might have been assigned to the wrong cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pds5pWkWk7Xl"
   },
   "outputs": [],
   "source": [
    "dbscan_df = data_pca.copy()\n",
    "dbscan_df1 = dbscan_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z55Hu-SVk7Xl"
   },
   "outputs": [],
   "source": [
    "# Initializing lists\n",
    "eps_value = [2,3]                       # Taking random eps value\n",
    "min_sample_values = [6,20]              # Taking random min_sample value\n",
    "\n",
    "# Creating a dictionary for each of the values in eps_value with min_sample_values\n",
    "res = {eps_value[i]: min_sample_values for i in range(len(eps_value))}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "efV8wJKjk7Xl"
   },
   "outputs": [],
   "source": [
    "# Finding the silhouette_score for each of the combination\n",
    "high_silhouette_avg = 0                                               # Assigning 0 to the high_silhouette_avg variable\n",
    "high_i_j = [0, 0]                                                     # Assigning 0's to the high_i_j list\n",
    "key = res.keys()                                                      # Assigning dictionary keys to a variable called key\n",
    "for i in key:\n",
    "    z = res[i]                                                        # Assigning dictionary values of each i to z\n",
    "    for j in z:\n",
    "        db = DBSCAN(eps = i, min_samples = j).fit(dbscan_df)          # Applying DBScan to each of the combinations in dictionary\n",
    "        core_samples_mask = np.zeros_like(db.labels_, dtype = bool)\n",
    "        core_samples_mask[db.core_sample_indices_] = True\n",
    "        labels = db.labels_\n",
    "        silhouette_avg = silhouette_score(dbscan_df, labels)           # Finding silhouette score \n",
    "        print( \n",
    "            \"For eps value =\" + str(i),\n",
    "            \"For min sample =\" + str(j),\n",
    "            \"The average silhoutte_score is :\",\n",
    "            silhouette_avg,                                            # Printing the silhouette score for each of the combinations\n",
    "        )\n",
    "        if high_silhouette_avg < silhouette_avg:                       # If the silhouette score is greater than 0 or the previous score, it will get appended to the high_silhouette_avg list with its combination of i and j              \n",
    "            high_i_j[0] = i\n",
    "            high_i_j[1] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eCtmbwQ6k7Xm"
   },
   "outputs": [],
   "source": [
    "# Printing the highest silhouette score\n",
    "print(\n",
    "    \"Highest_silhoutte_avg is {} for eps = {} and min sample = {}\".format(\n",
    "        high_silhouette_avg, high_i_j[0], high_i_j[1]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-4BAPJPxk7Xm"
   },
   "outputs": [],
   "source": [
    "# Applying DBSCAN with the hyperparmeter values that we got\n",
    "\n",
    "# Fit DBSCAN algorithm with the above hyperparameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PoHzFL-6k7Xm"
   },
   "outputs": [],
   "source": [
    "# Creating a copy of the original data\n",
    "df5 = df.copy()\n",
    "\n",
    "# Add DBSCAN cluster labels to dbscan data\n",
    "dbscan_df1[\"db_segments\"] = ________________\n",
    "\n",
    "# Add DBSCAN cluster labels to original data\n",
    "df5[\"db_segments\"] =  ___________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XB446gVFk7Xm"
   },
   "source": [
    "### **Cluster Profiling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wLyVGVyVk7Xm"
   },
   "outputs": [],
   "source": [
    "# Take the cluster-wise mean of all the variables. Hint: First group 'df5' by cluster labels column and then find mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WIT_gs7Wk7Xn"
   },
   "outputs": [],
   "source": [
    "# Create the \"count_in_each_segment\" column in hierarchical cluster profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s4j5Ax1Yk7Xn"
   },
   "outputs": [],
   "source": [
    "# Highlight the maximum average value among all the clusters for each of the variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5mEaHlW-k7Xn"
   },
   "source": [
    "**Think about it:**\n",
    "\n",
    "- Changing the eps and min sample values will result in different DBSCAN results? Can we try more value for eps and min_sample?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_KHRelmEk7Xn"
   },
   "source": [
    "**Observations and Insights:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8WjjVdFMk7Xo"
   },
   "source": [
    "### **Choosing the Best Algorithm**\n",
    "\n",
    "- Since cluster profiles are the same for every algorithm except DBSCAN, it is difficult to choose the best algorithm. We can compute the silhouette score to choose the best algorithm among all the algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dU1hbOxuk7Xo"
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters = 4, random_state = 1, n_init = 'auto')        # Initializing K-Means with number of clusters as 4 and random_state = 1\n",
    "\n",
    "preds = kmeans.fit_predict((data_pca))                   # Fitting and predicting K-Means on data_pca\n",
    "\n",
    "score = silhouette_score(data_pca, preds)                # Calculating the silhouette score\n",
    "\n",
    "print(score)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uVASHRAOk7Xo"
   },
   "outputs": [],
   "source": [
    "# Initialize K-Medoids with number of clusters as 4 and random_state = 1\n",
    "\n",
    "# Fitting and predicting K-Medoids on data_pca\n",
    "\n",
    "# Calculate the silhouette score\n",
    "\n",
    "# Print the score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2vWg5ZXOk7Xo"
   },
   "outputs": [],
   "source": [
    "# Initialize Agglomerative Clustering with distance as Euclidean, linkage as ward with clusters = 4\n",
    "\n",
    "# Fitting and predicting HC algorithm on data_pca  \n",
    "\n",
    "# Calculate the silhouette score\n",
    "\n",
    "# Print the score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9_8hdP_Qk7Xo"
   },
   "outputs": [],
   "source": [
    "# Initialize Gaussian Mixture algorithm with number of clusters as 4 and random_state = 1\n",
    "\n",
    "# Fitting and predicting Gaussian Mixture algorithm on data_pca\n",
    "\n",
    "# Calculate the silhouette score\n",
    "\n",
    "# Print the score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JwfS-ZEjk7Xo"
   },
   "source": [
    "**Think about it:**\n",
    "\n",
    "- Which is the best algorithm here among all the algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nxrEHj3ihmWO"
   },
   "source": [
    "## **Conclusion:**__\n",
    "\n",
    "\n",
    "## **Recommendations:**__"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
