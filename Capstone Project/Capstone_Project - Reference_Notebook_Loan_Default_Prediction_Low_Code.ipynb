{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_iHEvciuTB9"
   },
   "source": [
    "# **Loan Default Prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKyzwpUiuTB2"
   },
   "source": [
    "## **Problem Definition**\n",
    "\n",
    "### **The Context:**\n",
    "\n",
    " - Why is this problem important to solve?\n",
    "\n",
    "### **The objective:**\n",
    "\n",
    " - What is the intended goal?\n",
    "\n",
    "### **The key questions:**\n",
    "\n",
    "- What are the key questions that need to be answered?\n",
    "\n",
    "### **The problem formulation**:\n",
    "\n",
    "- What is it that we are trying to solve using data science?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qEHRGpcdo-KO"
   },
   "source": [
    "## **Data Description:**\n",
    "The Home Equity dataset (HMEQ) contains baseline and loan performance information for 5,960 recent home equity loans. The target (BAD) is a binary variable that indicates whether an applicant has ultimately defaulted or has been severely delinquent. This adverse outcome occurred in 1,189 cases (20 percent). 12 input variables were registered for each applicant.\n",
    "\n",
    "\n",
    "* **BAD:** 1 = Client defaulted on loan, 0 = loan repaid\n",
    "\n",
    "* **LOAN:** Amount of loan approved.\n",
    "\n",
    "* **MORTDUE:** Amount due on the existing mortgage.\n",
    "\n",
    "* **VALUE:** Current value of the property. \n",
    "\n",
    "* **REASON:** Reason for the loan request. (HomeImp = home improvement, DebtCon= debt consolidation which means taking out a new loan to pay off other liabilities and consumer debts) \n",
    "\n",
    "* **JOB:** The type of job that loan applicant has such as manager, self, etc.\n",
    "\n",
    "* **YOJ:** Years at present job.\n",
    "\n",
    "* **DEROG:** Number of major derogatory reports (which indicates a serious delinquency or late payments). \n",
    "\n",
    "* **DELINQ:** Number of delinquent credit lines (a line of credit becomes delinquent when a borrower does not make the minimum required payments 30 to 60 days past the day on which the payments were due). \n",
    "\n",
    "* **CLAGE:** Age of the oldest credit line in months. \n",
    "\n",
    "* **NINQ:** Number of recent credit inquiries. \n",
    "\n",
    "* **CLNO:** Number of existing credit lines.\n",
    "\n",
    "* **DEBTINC:** Debt-to-income ratio (all your monthly debt payments divided by your gross monthly income. This number is one way lenders measure your ability to manage the monthly payments to repay the money you plan to borrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LwRxhSDi4Mcc"
   },
   "source": [
    "## <b>Important Notes</b>\n",
    "\n",
    "- This notebook can be considered a guide to refer to while solving the problem. The evaluation will be as per the Rubric shared for the Milestone. Unlike previous courses, it does not follow the pattern of the graded questions in different sections. This notebook would give you a direction on what steps need to be taken in order to get a viable solution to the problem. Please note that this is just one way of doing this. There can be other 'creative' ways to solve the problem and we urge you to feel free and explore them as an 'optional' exercise. \n",
    "\n",
    "- In the notebook, there are markdowns cells called - Observations and Insights. It is a good practice to provide observations and extract insights from the outputs.\n",
    "\n",
    "- The naming convention for different variables can vary. Please consider the code provided in this notebook as a sample code.\n",
    "\n",
    "- All the outputs in the notebook are just for reference and can be different if you follow a different approach.\n",
    "\n",
    "- There are sections called **Think About It** in the notebook that will help you get a better understanding of the reasoning behind a particular technique/step. Interested learners can take alternative approaches if they want to explore different techniques. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DcZcGaZruTB-"
   },
   "source": [
    "### **Import the necessary libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pvj9AGJtuTB_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score,precision_score,recall_score,f1_score\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MeR8oNrJuTCB"
   },
   "source": [
    "### **Read the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x-_l0eJsuTCC"
   },
   "outputs": [],
   "source": [
    "hm=pd.read_csv(\"hmeq.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u6CaY5DauTCD"
   },
   "outputs": [],
   "source": [
    "# Copying data to another variable to avoid any changes to original data\n",
    "data=hm.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T9ykJzCRuTCD"
   },
   "source": [
    "### **Print the first and last 5 rows of the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8BbtCu5QuTCE"
   },
   "outputs": [],
   "source": [
    "# Display first five rows\n",
    "# Remove ___________ and complete the code\n",
    "\n",
    "______________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lt5d7NJRuTCE"
   },
   "outputs": [],
   "source": [
    "# Display last 5 rows\n",
    "# Remove ___________ and complete the code\n",
    "_________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XJKmSsjtuTCF"
   },
   "source": [
    "### **Understand the shape of the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HspKejinuTCF"
   },
   "outputs": [],
   "source": [
    "# Check the shape of the data\n",
    "# Remove ___________ and complete the code\n",
    "\n",
    "_________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cScgHgaPuTCG"
   },
   "source": [
    "**Insights ________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HGRNlowYuTCG"
   },
   "source": [
    "### **Check the data types of the columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rA_zvhOjuTCH"
   },
   "outputs": [],
   "source": [
    "# Check info of the data\n",
    "# Remove ___________ and complete the code\n",
    "_____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PfS2SKZYuTCI"
   },
   "source": [
    "**Insights ______________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8RQwiyX5uTCI"
   },
   "source": [
    "### **Check for missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BkKU4OT5uTCJ"
   },
   "outputs": [],
   "source": [
    "# Analyse missing values - Hint: use isnull() function\n",
    "# Remove ___________ and complete the code\n",
    "________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dteGNwLEuTCJ"
   },
   "outputs": [],
   "source": [
    "# Check the percentage of missing values in the each column.\n",
    "# Hint: divide the result from the previous code by the number of rows in the dataset\n",
    "# Remove ___________ and complete the code\n",
    "\n",
    "________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VpLSU6ApuTCK"
   },
   "source": [
    "**Insights ________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MEwi3CxXuTCL"
   },
   "source": [
    "### **Think about it:**\n",
    "- We found the total number of missing values and the percentage of missing values, which is better to consider?\n",
    "- What can be the limit for % missing values in a column in order to avoid it and what are the challenges associated with filling them and avoiding them? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R61QJ_xLuTCM"
   },
   "source": [
    "**We can convert the object type columns to categories**\n",
    "\n",
    "`converting \"objects\" to \"category\" reduces the data space required to store the dataframe`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PgMjKOaRuTCM"
   },
   "source": [
    "### **Convert the data types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hrNDixcVuTCN"
   },
   "outputs": [],
   "source": [
    "cols = data.select_dtypes(['object']).columns.tolist()\n",
    "\n",
    "#adding target variable to this list as this is an classification problem and the target variable is categorical\n",
    "\n",
    "cols.append('BAD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gUOaQH76uTCR"
   },
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W7jha4QcuTCS"
   },
   "outputs": [],
   "source": [
    "# Changing the data type of object type column to category. hint use astype() function\n",
    "# remove ___________ and complete the code\n",
    "\n",
    "for i in cols:\n",
    "    data[i] = data[i]._______________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jla4lGthuTCT"
   },
   "outputs": [],
   "source": [
    "# Checking the info again and the datatype of different variable\n",
    "# remove ___________ and complete the code\n",
    "\n",
    "__________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHTODkjLuTCT"
   },
   "source": [
    "### **Analyze Summary Statistics of the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2w7JWBV5uTCT"
   },
   "outputs": [],
   "source": [
    "# Analyze the summary statistics for numerical variables\n",
    "# Remove ___________ and complete the code\n",
    "\n",
    "______________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g51vGZAGuTCT"
   },
   "source": [
    "**Insights ______________**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IBo2gAezuTCU"
   },
   "outputs": [],
   "source": [
    "# Check summary for categorical data - Hint: inside describe function you can use the argument include=['category']\n",
    "# Remove ___________ and complete the code\n",
    "\n",
    "data.describe(_________________).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h9GGlAZTuTCU"
   },
   "source": [
    "**Insights _____________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VWcWZ_pDuTCU"
   },
   "source": [
    "**Let's look at the unique values in all the categorical variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OwmmUgHhuTCV"
   },
   "outputs": [],
   "source": [
    "# Checking the count of unique values in each categorical column \n",
    "# Remove ___________ and complete the code\n",
    "\n",
    "cols_cat= data.select_dtypes(['category'])\n",
    "\n",
    "for i in cols_cat.columns:\n",
    "    print('Unique values in',i, 'are :')\n",
    "    print(______________________)\n",
    "    print('*'*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8sh7FE6kuTCV"
   },
   "source": [
    "**Insights _____________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KVqJU9nluTCV"
   },
   "source": [
    "### **Think about it**\n",
    "- The results above gave the absolute count of unique values in each categorical column. Are absolute values a good measure? \n",
    "- If not, what else can be used? Try implementing that. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ZcMbNvZuTCW"
   },
   "source": [
    "## **Exploratory Data Analysis (EDA) and Visualization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65yxFJFVuTCW"
   },
   "source": [
    "## **Univariate Analysis**\n",
    "\n",
    "Univariate analysis is used to explore each variable in a data set, separately. It looks at the range of values, as well as the central tendency of the values. It can be done for both numerical and categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4whDGVaBuTCW"
   },
   "source": [
    "### **1. Univariate Analysis - Numerical Data**\n",
    "Histograms and box plots help to visualize and describe numerical data. We use box plot and histogram to analyze the numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gcycXyj3uTCX"
   },
   "outputs": [],
   "source": [
    "# While doing uni-variate analysis of numerical variables we want to study their central tendency and dispersion.\n",
    "# Let us write a function that will help us create boxplot and histogram for any input numerical variable.\n",
    "# This function takes the numerical column as the input and return the boxplots and histograms for the variable.\n",
    "# Let us see if this help us write faster and cleaner code.\n",
    "def histogram_boxplot(feature, figsize=(15,10), bins = None):\n",
    "    \"\"\" Boxplot and histogram combined\n",
    "    feature: 1-d feature array\n",
    "    figsize: size of fig (default (9,8))\n",
    "    bins: number of bins (default None / auto)\n",
    "    \"\"\"\n",
    "    f2, (ax_box2, ax_hist2) = plt.subplots(nrows = 2, # Number of rows of the subplot grid= 2\n",
    "                                           sharex = True, # x-axis will be shared among all subplots\n",
    "                                           gridspec_kw = {\"height_ratios\": (.25, .75)}, \n",
    "                                           figsize = figsize \n",
    "                                           ) # creating the 2 subplots\n",
    "    sns.boxplot(feature, ax=ax_box2, showmeans=True, color='violet') # boxplot will be created and a star will indicate the mean value of the column\n",
    "    sns.histplot(feature, kde=F, ax=ax_hist2, bins=bins,palette=\"winter\") if bins else sns.histplot(feature, kde=False, ax=ax_hist2) # For histogram\n",
    "    ax_hist2.axvline(np.mean(feature), color='green', linestyle='--') # Add mean to the histogram\n",
    "    ax_hist2.axvline(np.median(feature), color='black', linestyle='-') # Add median to the histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "blkJiWpZuTCX"
   },
   "source": [
    "#### Using the above function, let's first analyze the Histogram and Boxplot for LOAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Opq44Th3uTCY"
   },
   "outputs": [],
   "source": [
    "# Build the histogram boxplot for Loan\n",
    "histogram_boxplot(data['LOAN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lMRlVrhUuTCY"
   },
   "source": [
    "**Insights __________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQPk1YdYuTCY"
   },
   "source": [
    "#### **Note:** As done above, analyze Histogram and Boxplot for other variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TwsB4Ls7uTCY"
   },
   "source": [
    "**Insights ____________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35i8LgeWuTCY"
   },
   "source": [
    "### **2. Univariate Analysis - Categorical Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gJkymNTmuTCZ"
   },
   "outputs": [],
   "source": [
    "# Function to create barplots that indicate percentage for each category.\n",
    "\n",
    "def perc_on_bar(plot, feature):\n",
    "    '''\n",
    "    plot\n",
    "    feature: categorical feature\n",
    "    the function won't work if a column is passed in hue parameter\n",
    "    '''\n",
    "\n",
    "    total = len(feature) # length of the column\n",
    "    for p in ax.patches:\n",
    "        percentage = '{:.1f}%'.format(100 * p.get_height()/total) # percentage of each class of the category\n",
    "        x = p.get_x() + p.get_width() / 2 - 0.05 # width of the plot\n",
    "        y = p.get_y() + p.get_height()           # height of the plot\n",
    "        ax.annotate(percentage, (x, y), size = 12) # annotate the percentage \n",
    "        \n",
    "    plt.show() # show the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XtWPhW6AuTCZ"
   },
   "source": [
    "#### Analyze Barplot for DELINQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "avQHwcT3uTCZ"
   },
   "outputs": [],
   "source": [
    "#Build barplot for DELINQ\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "ax = sns.countplot(x=data[\"DELINQ\"],palette='winter')\n",
    "perc_on_bar(ax,data[\"DELINQ\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPJ7-pbKuTCZ"
   },
   "source": [
    "**Insights ________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "igI2dP6wuTCa"
   },
   "source": [
    "#### **Note:** As done above, analyze Histogram and Boxplot for other variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YdmMDqB0uTCa"
   },
   "source": [
    "**Insights _____________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jg5IFtbouTCa"
   },
   "source": [
    "## **Bivariate Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bj9lXxzWuTCa"
   },
   "source": [
    "### **Bivariate Analysis: Continuous and Categorical Variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RcrXKyzxuTCb"
   },
   "source": [
    "#### Analyze BAD vs Loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VAs0KdILuTCb"
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x=data[\"BAD\"],y=data['LOAN'],palette=\"PuBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjt6hgGxuTCc"
   },
   "source": [
    "**Insights ______**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5Uz1rqnuTCc"
   },
   "source": [
    "#### **Note:** As shown above, perform Bi-Variate Analysis on different pair of Categorical and continuous variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eucYnvKuTCc"
   },
   "source": [
    "### **Bivariate Analysis: Two Continuous Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tNeY-6-fuTCc"
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data[\"VALUE\"],data['MORTDUE'],palette=\"PuBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-wGIbSKuTCd"
   },
   "source": [
    "**Insights: _____**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAs34FMbuTCd"
   },
   "source": [
    "#### **Note:** As shown above, perform Bivariate Analysis on different pairs of continuous variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tTvwzDBPuTCe"
   },
   "source": [
    "**Insights ____________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ce5BjPB1uTCf"
   },
   "source": [
    "### **Bivariate Analysis:  BAD vs Categorical Variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iuyPa6QquTCi"
   },
   "source": [
    "**The stacked bar chart (aka stacked bar graph)** extends the standard bar chart from looking at numeric values across one categorical variable to two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oohHgpYuuTCi"
   },
   "outputs": [],
   "source": [
    "### Function to plot stacked bar charts for categorical columns\n",
    "\n",
    "def stacked_plot(x):\n",
    "    sns.set(palette='nipy_spectral')\n",
    "    tab1 = pd.crosstab(x,data['BAD'],margins=True)\n",
    "    print(tab1)\n",
    "    print('-'*120)\n",
    "    tab = pd.crosstab(x,data['BAD'],normalize='index')\n",
    "    tab.plot(kind='bar',stacked=True,figsize=(10,5))\n",
    "    plt.legend(loc='lower left', frameon=False)\n",
    "    plt.legend(loc=\"upper left\", bbox_to_anchor=(1,1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bv2ZSN0fuTCj"
   },
   "source": [
    "#### Plot stacked bar plot for for LOAN and REASON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Duk0xjTFuTCk"
   },
   "outputs": [],
   "source": [
    "# Plot stacked bar plot for BAD and REASON\n",
    "stacked_plot(data['REASON'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "itlGd1rSuTCl"
   },
   "source": [
    "**Insights ____________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fq0ReWniuTCl"
   },
   "source": [
    "#### **Note:** As shown above, perform Bivariate Analysis on different pairs of Categorical vs BAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YLPwb-K6uTCm"
   },
   "source": [
    "**Insights ___________________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pc9wZJcGuTCm"
   },
   "source": [
    "### **Multivariate Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "htEKKZl0uTCn"
   },
   "source": [
    "#### Analyze Correlation Heatmap for Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FHenIjI1uTCo"
   },
   "outputs": [],
   "source": [
    "# Separating numerical variables\n",
    "numerical_col = data.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "# Build correlation matrix for numerical columns\n",
    "# Remove ___________ and complete the code\n",
    "\n",
    "corr = data[___________]._________________\n",
    "\n",
    "# plot the heatmap\n",
    "# Remove ___________ and complete the code\n",
    "\n",
    "plt.figure(figsize=(16,12))\n",
    "sns.heatmap(___________,cmap='coolwarm',vmax=1,vmin=-1,\n",
    "        fmt=\".2f\",\n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UVpwy9KouTCo"
   },
   "outputs": [],
   "source": [
    "# Build pairplot for the data with hue = 'BAD'\n",
    "# Remove ___________ and complete the code\n",
    "\n",
    "__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTN4DIW4uTCp"
   },
   "source": [
    "### **Think about it**\n",
    "- Are there missing values and outliers in the dataset? If yes, how can you treat them? \n",
    "- Can you think of different ways in which this can be done and when to treat these outliers or not?\n",
    "- Can we create new features based on Missing values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEjMlq0quTCp"
   },
   "source": [
    "#### Treating Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r-fykwEMuTCp"
   },
   "outputs": [],
   "source": [
    "def treat_outliers(df,col):\n",
    "    '''\n",
    "    treats outliers in a varaible\n",
    "    col: str, name of the numerical varaible\n",
    "    df: data frame\n",
    "    col: name of the column\n",
    "    '''\n",
    "    \n",
    "    Q1=______________ # 25th quantile\n",
    "    Q3=_____________  # 75th quantile\n",
    "    IQR=___________   # IQR Range\n",
    "    Lower_Whisker = ____________  #define lower whisker\n",
    "    Upper_Whisker = ____________  # define upper Whisker\n",
    "    df[col] = np.clip(df[col], Lower_Whisker, Upper_Whisker) # all the values samller than Lower_Whisker will be assigned value of Lower_whisker \n",
    "                                                            # and all the values above upper_whishker will be assigned value of upper_Whisker \n",
    "    return df\n",
    "\n",
    "def treat_outliers_all(df, col_list):\n",
    "    '''\n",
    "    treat outlier in all numerical varaibles\n",
    "    col_list: list of numerical varaibles\n",
    "    df: data frame\n",
    "    '''\n",
    "    for c in col_list:\n",
    "        df = treat_outliers(df,c)\n",
    "        \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z5PklUrZuTCq"
   },
   "outputs": [],
   "source": [
    "df_raw = data.copy()\n",
    "\n",
    "numerical_col = df_raw.select_dtypes(include=np.number).columns.tolist()# getting list of numerical columns\n",
    "\n",
    "df = treat_outliers_all(df_raw,numerical_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jy520Nv-uTCq"
   },
   "source": [
    "#### Adding new columns in the dataset for each column which has missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-CJlYQ5KuTCr"
   },
   "outputs": [],
   "source": [
    "#For each column we create a binary flag for the row, if there is missing value in the row, then 1 else 0. \n",
    "def add_binary_flag(df,col):\n",
    "    '''\n",
    "    df: It is the dataframe\n",
    "    col: it is column which has missing values\n",
    "    It returns a dataframe which has binary falg for missing values in column col\n",
    "    '''\n",
    "    new_col = str(col)\n",
    "    new_col += '_missing_values_flag'\n",
    "    df[new_col] = df[col].isna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-FKPAmAjuTCr"
   },
   "outputs": [],
   "source": [
    "# list of columns that has missing values in it\n",
    "missing_col = [col for col in df.columns if df[col].isnull().any()]\n",
    "\n",
    "for colmn in missing_col:\n",
    "    add_binary_flag(df,colmn)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_tXbx-9cuTCr"
   },
   "source": [
    "#### Filling missing values in numerical columns with median and mode in categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fojOcAzyuTCs"
   },
   "outputs": [],
   "source": [
    "#  Treat Missing values in numerical columns with median and mode in categorical variables\n",
    "# Select numeric columns.\n",
    "num_data = df.select_dtypes('number')\n",
    "\n",
    "# Select string and object columns.\n",
    "cat_data = df.select_dtypes('category').columns.tolist()#df.select_dtypes('object')\n",
    "\n",
    "# Fill numeric columns with median.\n",
    "# Remove _________ and complete the code\n",
    "df[num_data.columns] = num_data._________________\n",
    "\n",
    "# Fill object columns with model.\n",
    "# Remove _________ and complete the code\n",
    "for column in cat_data:\n",
    "    mode = df[column].mode()[0]\n",
    "    df[column] = df[column].____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eG_XM04vuTCs"
   },
   "source": [
    "## **Important Insights from EDA**\n",
    "\n",
    "What are the the most important observations and insights from the data based on the EDA performed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cdqhtr8yuS-L"
   },
   "source": [
    "## **Model Building - Approach**\n",
    "1. Data preparation\n",
    "2. Partition the data into train and test set\n",
    "3. Fit on the train data\n",
    "4. Tune the model and prune the tree, if required\n",
    "5. Test the model on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7QgAXSWfuS-M"
   },
   "source": [
    "## **Data Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSUhpu0fuS-M"
   },
   "source": [
    "### **Separating the target variable from other variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2_IZEwKruS-N"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "# Drop the dependent variable from the dataframe and create the X(independent variable) matrix\n",
    "# Remove _________ and complete the code\n",
    "X = ____________________\n",
    "\n",
    "# Create dummy variables for the categorical variables - Hint: use the get_dummies() function\n",
    "# Remove _________ and complete the code\n",
    "X = ______________________\n",
    "\n",
    "# Create y(dependent varibale)\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "y = ___________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "La_3-i5quS-P"
   },
   "source": [
    "### **Splitting the data into 70% train and 30% test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sgF5mdtCuS-P"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "# Split the data into training and test set\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "\n",
    "_____________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "181uwUApuS-R"
   },
   "source": [
    "### **Think about it** \n",
    "- You can try different splits like 70:30 or 80:20 as per your choice. Does this change in split affect the performance?\n",
    "- If the data is imbalanced, can you make the split more balanced and if yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EVxWdZc_uS-S"
   },
   "source": [
    "## **Model Evaluation Criterion**\n",
    "\n",
    "#### After understanding the problem statement, think about which evaluation metrics to consider and why. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oNVO2cX_uS-V"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "#creating metric function \n",
    "def metrics_score(actual, predicted):\n",
    "    print(classification_report(actual, predicted))\n",
    "    cm = confusion_matrix(actual, predicted)\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.heatmap(cm, annot=True,  fmt='.2f', xticklabels=['Not Eligible', 'Eligible'], yticklabels=['Not Eligible', 'Eligible'])\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eTdaiYeMuS-a"
   },
   "source": [
    "### **Build a Logistic Regression Model** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OkEsDyg-uS-b"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "# Defining the Logistic regression model\n",
    "# Remove _________ and complete the code\n",
    "____________\n",
    "\n",
    "# Fitting the model on the training data \n",
    "# Remove _________ and complete the code\n",
    "\n",
    "________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZj-by40uS-c"
   },
   "source": [
    "#### Checking the performance on the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ga0ZoViNuS-d"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "#Predict for train set\n",
    "# Remove _________ and complete the code\n",
    "________________\n",
    "\n",
    "#checking the performance on the train dataset\n",
    "# Remove _________ and complete the code\n",
    "_________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ouIrxTDuS-f"
   },
   "source": [
    "#### Checking the performance on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YtQ3PUoAuS-f"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "#Predict for test set\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "_______________________\n",
    "\n",
    "#checking the performance on the test dataset\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "_____________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0Uix_PRuS-g"
   },
   "source": [
    "**Observations: __________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1WM0T3vuS-g"
   },
   "source": [
    "#### Let's check the coefficients, and check which variables are important and how they affect the process of loan approval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uelo699muS-h"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "# Printing the coefficients of logistic regression\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "\n",
    "_____________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eQAjCv4MuS-i"
   },
   "source": [
    "**Insights ________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7X4-6d-uS-i"
   },
   "source": [
    "### **Think about it:**\n",
    "- The above Logistic regression model was build on the threshold of 0.5, can we use different threshold?\n",
    "- How to get an optimal threshold and which curve will help you achieve?\n",
    "- How does, accuracy, precision and recall change on the threshold?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qn8IjxI7uS-j"
   },
   "source": [
    "### **Build a Decision Tree Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOYH3hhauS-l"
   },
   "source": [
    "### **Think about it:**\n",
    "- In Logistic regression we treated the outliers and built the model, should we do the same for tree based models or not? If not, why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LcsyeOmMuS-n"
   },
   "source": [
    "#### Data Preparation for the tree based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "syncXvl-uS-n"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "# Add binary flags\n",
    "# List of columns that has missing values in it\n",
    "missing_col = [col for col in data.columns if data[col].isnull().any()]\n",
    "\n",
    "for colmn in missing_col:\n",
    "    add_binary_flag(data,colmn)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IUaxm207uS-o"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "#  Treat Missing values in numerical columns with median and mode in categorical variables\n",
    "# Select numeric columns.\n",
    "num_data = data.select_dtypes('number')\n",
    "\n",
    "# Select string and object columns.\n",
    "cat_data = data.select_dtypes('category').columns.tolist()#df.select_dtypes('object')\n",
    "\n",
    "# Fill numeric columns with median.\n",
    "# Remove _________ and complete the code\n",
    "data[num_data.columns] = num_data._________________\n",
    "\n",
    "# Fill object columns with model.\n",
    "# Remove _________ and complete the code\n",
    "for column in cat_data:\n",
    "    mode = data[column].mode()[0]\n",
    "    data[column] = data[column].____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aO6ZhcAGuS-o"
   },
   "source": [
    "#### Separating the target variable y and independent variable x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t63yXVu_uS-p"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "# Drop dependent variable from dataframe and create the X(independent variable) matrix\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "X = ____________________\n",
    "\n",
    "# Create dummy variables for the categorical variables - Hint: use the get_dummies() function\n",
    "# Remove _________ and complete the code\n",
    "X = ______________________\n",
    "\n",
    "# Create y(dependent varibale)\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "y = ___________________________-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_npczaCuS-p"
   },
   "source": [
    "#### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5AEW52XOuS-p"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "# Split the data into training and test set\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "\n",
    "______________ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_n6jIx9yuS-q"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "#Defining Decision tree model with class weights class_weight={0: 0.2, 1: 0.8}\n",
    "# Remove ___________ and complete the code\n",
    "\n",
    "_______________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BongVVR0uS-q"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "#fitting Decision tree model\n",
    "# Remove ___________ and complete the code\n",
    "_______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n85UqWwJuS-q"
   },
   "source": [
    "#### Checking the performance on the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z2noEOCLuS-r"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "# Checking performance on the training data\n",
    "# Remove ___________ and complete the code\n",
    "\n",
    "_______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hD_3cgYvuS-r"
   },
   "source": [
    "#### Checking the performance on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ajlKdERCuS-r"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "# Checking performance on the testing data\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "_______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUDAFw4cuS-r"
   },
   "source": [
    "**Insights _____________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7GtaZ2_juS-s"
   },
   "source": [
    "### **Think about it:**\n",
    "- Can we improve this model? \n",
    "- How to get optimal parameters in order to get the best possible results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kjPqLicruS-s"
   },
   "source": [
    "### **Decision Tree - Hyperparameter Tuning**\n",
    "\n",
    "* Hyperparameter tuning is tricky in the sense that **there is no direct way to calculate how a change in the hyperparameter value will reduce the loss of your model**, so we usually resort to experimentation. We'll use Grid search to perform hyperparameter tuning.\n",
    "* **Grid search is a tuning technique that attempts to compute the optimum values of hyperparameters.** \n",
    "* **It is an exhaustive search** that is performed on the specific parameter values of a model.\n",
    "* The parameters of the estimator/model used to apply these methods are **optimized by cross-validated grid-search** over a parameter grid.\n",
    "\n",
    "**Criterion {“gini”, “entropy”}**\n",
    "\n",
    "The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “entropy” for the information gain.\n",
    "\n",
    "**max_depth** \n",
    "\n",
    "The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n",
    "\n",
    "**min_samples_leaf**\n",
    "\n",
    "The minimum number of samples is required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.\n",
    "\n",
    "You can learn about more Hyperpapameters on this link and try to tune them. \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWj_L0VnuS-s"
   },
   "source": [
    "#### Using GridSearchCV for Hyperparameter tuning on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_v-aQT3SuS-s"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "# Choose the type of classifier. \n",
    "# Remove _________ and complete the code\n",
    "________________\n",
    "\n",
    "\n",
    "# Grid of parameters to choose from\n",
    "# Remove _________ and complete the code\n",
    "________________\n",
    "\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "# Remove _________ and complete the code\n",
    "_________________\n",
    "\n",
    "\n",
    "# Run the grid search\n",
    "# Remove _________ and complete the code\n",
    "_________________\n",
    "\n",
    "\n",
    "# Fit the GridSearch on train dataset\n",
    "# Remove _________ and complete the code\n",
    "__________________\n",
    "\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "# Remove _________ and complete the code\n",
    "_________________\n",
    "\n",
    "\n",
    "# Fit the best algorithm to the data. \n",
    "# Remove _________ and complete the code\n",
    "_________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Nd9-d44uS-t"
   },
   "source": [
    "#### Checking the performance on the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RJuFkZwluS-t"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "# Checking performance on the training data based on the tuned model\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0e6nxW5zuS-t"
   },
   "source": [
    "#### Checking the performance on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PXhwj5UtuS-t"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "# Checking performance on the testing data based on the tuned model\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "_________________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sskSDE2RuS-u"
   },
   "source": [
    "**Insights ___________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YgPleHWHuS-u"
   },
   "source": [
    "#### Plotting the Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W9alMIpUuS-u"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "# Plot the decision  tree and analyze it to build the decision rule\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "\n",
    "____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DXlpWpwquS-u"
   },
   "source": [
    "#### Deduce the business rules apparent from the Decision Tree and write them down: _____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4IG8BCgluS-u"
   },
   "source": [
    "### **Building a Random Forest Classifier**\n",
    "\n",
    "**Random Forest is a bagging algorithm where the base models are Decision Trees.** Samples are taken from the training data and on each sample a decision tree makes a prediction. \n",
    "\n",
    "**The results from all the decision trees are combined together and the final prediction is made using voting or averaging.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2CS_aJmluS-u"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "# Defining Random forest CLassifier\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "___________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9MGpWZ8buS-v"
   },
   "source": [
    "#### Checking the performance on the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E8CrEYjsuS-v"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "#Checking performance on the training data\n",
    "# Remove _________ and complete the code\n",
    "_______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DaH64bDMuS-v"
   },
   "source": [
    "#### Checking the performance on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "At9Nu5KkuS-v"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "# Checking performance on the test data\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "_______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UqQfEbEKuS-v"
   },
   "source": [
    "**Observations: __________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HCBcKpE3uS-w"
   },
   "source": [
    "### **Build a Random Forest model with Class Weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bRsYlxyXuS-w"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "# Defining Random Forest model with class weights class_weight={0: 0.2, 1: 0.8}\n",
    "\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "_____________________________\n",
    "\n",
    "# Fitting Random Forest model\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "_______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJP3x99guS-w"
   },
   "source": [
    "#### Checking the performance on the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xg6LNpXPuS-w",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "# Checking performance on the train data\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKMujUrwuS-w"
   },
   "source": [
    "#### Checking the performance on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ehxp227duS-x"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "# Checking performance on the test data\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HU_b2tY3uS-x"
   },
   "source": [
    "### **Think about it:**\n",
    "- Can we try different weights?\n",
    "- If yes, should we increase or decrease class weights for different classes? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nFRFdf0KuS-x"
   },
   "source": [
    "### **Tuning the Random Forest**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-pHpGmcquS-x"
   },
   "source": [
    "* Hyperparameter tuning is tricky in the sense that **there is no direct way to calculate how a change in the hyperparameter value will reduce the loss of your model**, so we usually resort to experimentation. We'll use Grid search to perform hyperparameter tuning.\n",
    "* **Grid search is a tuning technique that attempts to compute the optimum values of hyperparameters.** \n",
    "* **It is an exhaustive search** that is performed on the specific parameter values of a model.\n",
    "* The parameters of the estimator/model used to apply these methods are **optimized by cross-validated grid-search** over a parameter grid.\n",
    "\n",
    "\n",
    "**n_estimators**: The number of trees in the forest.\n",
    "\n",
    "**min_samples_split**: The minimum number of samples required to split an internal node:\n",
    "\n",
    "**min_samples_leaf**: The minimum number of samples required to be at a leaf node. \n",
    "\n",
    "**max_features{“auto”, “sqrt”, “log2”, 'None'}**: The number of features to consider when looking for the best split.\n",
    "\n",
    "- If “auto”, then max_features=sqrt(n_features).\n",
    "\n",
    "- If “sqrt”, then max_features=sqrt(n_features) (same as “auto”).\n",
    "\n",
    "- If “log2”, then max_features=log2(n_features).\n",
    "\n",
    "- If None, then max_features=n_features.\n",
    "\n",
    "You can learn more about Random Forest Hyperparameters from the link given below and try to tune them\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Yju5_bLuS-y"
   },
   "source": [
    "#### **Warning:** This may take a long time depending on the parameters you tune. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4eF3pM_0uS-y"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "# Choose the type of classifier. \n",
    "# Remove _________ and complete the code\n",
    "________________\n",
    "\n",
    "\n",
    "# Grid of parameters to choose from\n",
    "# Remove _________ and complete the code\n",
    "________________\n",
    "\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "# Remove _________ and complete the code\n",
    "_________________\n",
    "\n",
    "\n",
    "# Run the grid search\n",
    "# Remove _________ and complete the code\n",
    "_________________\n",
    "\n",
    "\n",
    "#fit the GridSearch on train dataset\n",
    "# Remove _________ and complete the code\n",
    "__________________\n",
    "\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "# Remove _________ and complete the code\n",
    "_________________\n",
    "\n",
    "\n",
    "# Fit the best algorithm to the data. \n",
    "# Remove _________ and complete the code\n",
    "_________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mawgr8A6uS-z"
   },
   "source": [
    "#### Checking the performance on the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gm8MPNCOuS-z"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "# Checking performance on the training data\n",
    "# Remove _________ and complete the code\n",
    "______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oepvVX5CuS-3"
   },
   "source": [
    "#### Checking the performance on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1PoLfAzauS-3"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "# Checking performace on test dataset\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "_________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2bhHvKnAuS-4"
   },
   "source": [
    "**Insights: _____**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pq9GKJxnuS-4"
   },
   "source": [
    "#### Plot the Feature importance of the tuned Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PeJMlclxuS-4"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "# importance of features in the tree building ( The importance of a feature is computed as the \n",
    "#(normalized) total reduction of the criterion brought by that feature. It is also known as the Gini importance )\n",
    "# Checking performace on test dataset\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "_________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z02xcdkcuS-5"
   },
   "source": [
    "### **Think about it:**\n",
    "- We have only built 3 models so far, Logistic Regression, Decision Tree and Random Forest \n",
    "- We can build other Machine Learning classification models like kNN, LDA, QDA or even Support Vector Machines (SVM).\n",
    "- Can we also perform feature engineering and create model features and build a more robust and accurate model for this problem statement? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fkR0P8HXuS-5"
   },
   "source": [
    "### **Comparing Model Performances**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pe6Pl8FVuS-6"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "def get_recall_score(model,flag=True,X_train=X_train,X_test=X_test):\n",
    "    '''\n",
    "    model : classifier to predict values of X\n",
    "\n",
    "    '''\n",
    "    a = [] # defining an empty list to store train and test results\n",
    "    pred_train = model.predict(X_train)\n",
    "    pred_test = model.predict(X_test)\n",
    "    train_recall = metrics.recall_score(y_train,pred_train)\n",
    "    test_recall = metrics.recall_score(y_test,pred_test)\n",
    "    a.append(train_recall) # adding train recall to list \n",
    "    a.append(test_recall) # adding test recall to list\n",
    "    \n",
    "    # If the flag is set to True then only the following print statements will be dispayed. The default value is set to True.\n",
    "    if flag == True: \n",
    "        print(\"Recall on training set : \",metrics.recall_score(y_train,pred_train))\n",
    "        print(\"Recall on test set : \",metrics.recall_score(y_test,pred_test))\n",
    "    \n",
    "    return a # returning the list with train and test scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aHrSzelxuS-6"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "##  Function to calculate precision score\n",
    "def get_precision_score(model,flag=True,X_train=X_train,X_test=X_test):\n",
    "    '''\n",
    "    model : classifier to predict values of X\n",
    "\n",
    "    '''\n",
    "    b = []  # defining an empty list to store train and test results\n",
    "    pred_train = model.predict(X_train)\n",
    "    pred_test = model.predict(X_test)\n",
    "    train_precision = metrics.precision_score(y_train,pred_train)\n",
    "    test_precision = metrics.precision_score(y_test,pred_test)\n",
    "    b.append(train_precision) # adding train precision to list\n",
    "    b.append(test_precision) # adding test precision to list\n",
    "    \n",
    "    # If the flag is set to True then only the following print statements will be dispayed. The default value is set to True.\n",
    "    if flag == True: \n",
    "        print(\"Precision on training set : \",metrics.precision_score(y_train,pred_train))\n",
    "        print(\"Precision on test set : \",metrics.precision_score(y_test,pred_test))\n",
    "\n",
    "    return b # returning the list with train and test scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8UbeXu-guS-7"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "##  Function to calculate accuracy score\n",
    "def get_accuracy_score(model,flag=True,X_train=X_train,X_test=X_test):\n",
    "    '''\n",
    "    model : classifier to predict values of X\n",
    "\n",
    "    '''\n",
    "    c = [] # defining an empty list to store train and test results\n",
    "    train_acc = model.score(X_train,y_train)\n",
    "    test_acc = model.score(X_test,y_test)\n",
    "    c.append(train_acc) # adding train accuracy to list\n",
    "    c.append(test_acc) # adding test accuracy to list\n",
    "    \n",
    "    # If the flag is set to True then only the following print statements will be dispayed. The default value is set to True.\n",
    "    if flag == True:\n",
    "        print(\"Accuracy on training set : \",model.score(X_train,y_train))\n",
    "        print(\"Accuracy on test set : \",model.score(X_test,y_test))\n",
    "    \n",
    "    return c # returning the list with train and test scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RZ9-xSnjuS-8"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "# Make the list of all the model names \n",
    "\n",
    "models = [___________________________]\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "# defining empty lists to add train and test results\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "recall_train = []\n",
    "recall_test = []\n",
    "precision_train = []\n",
    "precision_test = []\n",
    "\n",
    "# looping through all the models to get the accuracy,recall and precision scores\n",
    "for model in models:\n",
    "     # accuracy score\n",
    "    j = get_accuracy_score(model,False)\n",
    "    acc_train.append(j[0])\n",
    "    acc_test.append(j[1])\n",
    "\n",
    "    # recall score\n",
    "    k = get_recall_score(model,False)\n",
    "    recall_train.append(k[0])\n",
    "    recall_test.append(k[1])\n",
    "\n",
    "    # precision score\n",
    "    l = get_precision_score(model,False)\n",
    "    precision_train.append(l[0])\n",
    "    precision_test.append(l[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LHsbc4DMuS-8"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "# Mention the Model names in the list. for example 'Model': ['Decision Tree', 'Tuned Decision Tree'..... write tht names of all model built]\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "comparison_frame = pd.DataFrame({'Model':[______________________], \n",
    "                                          'Train_Accuracy': acc_train,\n",
    "                                          'Test_Accuracy': acc_test,\n",
    "                                          'Train_Recall': recall_train,\n",
    "                                          'Test_Recall': recall_test,\n",
    "                                          'Train_Precision': precision_train,\n",
    "                                          'Test_Precision': precision_test}) \n",
    "comparison_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YxFPX-pduS-9"
   },
   "source": [
    "**Insights: ________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPywjJo6uS-9"
   },
   "source": [
    "**1. Comparison of various techniques and their relative performance based on chosen Metric (Measure of success):** \n",
    "- How do different techniques perform? Which one is performing relatively better? Is there scope to improve the performance further?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eZdLjL5vuS-9"
   },
   "source": [
    "**2. Refined insights:** \n",
    "- What are the most meaningful insights relevant to the problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJRsBfsruS--"
   },
   "source": [
    "**3. Proposal for the final solution design:** \n",
    "- What model do you propose to be adopted? Why is this the best solution to adopt?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "MeR8oNrJuTCB",
    "T9ykJzCRuTCD",
    "XJKmSsjtuTCF",
    "HGRNlowYuTCG",
    "8RQwiyX5uTCI",
    "MEwi3CxXuTCL",
    "PgMjKOaRuTCM",
    "rHTODkjLuTCT",
    "KVqJU9nluTCV",
    "3ZcMbNvZuTCW",
    "4whDGVaBuTCW",
    "blkJiWpZuTCX",
    "NQPk1YdYuTCY",
    "35i8LgeWuTCY",
    "XtWPhW6AuTCZ",
    "igI2dP6wuTCa",
    "bj9lXxzWuTCa",
    "RcrXKyzxuTCb",
    "e5Uz1rqnuTCc",
    "1eucYnvKuTCc",
    "cAs34FMbuTCd",
    "ce5BjPB1uTCf",
    "bv2ZSN0fuTCj",
    "fq0ReWniuTCl",
    "pc9wZJcGuTCm",
    "RTN4DIW4uTCp",
    "zEjMlq0quTCp",
    "Jy520Nv-uTCq",
    "_tXbx-9cuTCr"
   ],
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
